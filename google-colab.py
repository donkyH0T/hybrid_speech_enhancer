import os
import glob
import numpy as np
import librosa
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import random
from tensorflow import keras
import shutil
import time
import warnings
from concurrent.futures import ThreadPoolExecutor
import multiprocessing

warnings.filterwarnings('ignore')

# === –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ===
SR = 16000
N_FFT = 512
HOP_LENGTH = 256
EPOCHS = 100
BATCH_SIZE = 8
TARGET_TIME_FRAMES = 256
FREQ_BINS = N_FFT // 2 + 1  # 257
MAX_SAMPLES = 1000
CONTEXT_FRAMES = 5

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –≤—ã—á–∏—Ç–∞–Ω–∏—è (–¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏)
SPEC_SUBTRACTION_ALPHA = 1.5
SPEC_SUBTRACTION_BETA = 0.1

def setup_colab_environment():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Google Colab"""
    print("="*60)
    print("–ù–ê–°–¢–†–û–ô–ö–ê GOOGLE COLAB")
    print("="*60)
    
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        print(f"‚úÖ GPU –¥–æ—Å—Ç—É–ø–µ–Ω: {len(gpus)} —É—Å—Ç—Ä–æ–π—Å—Ç–≤")
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ GPU: {e}")
    else:
        print("‚ùå GPU –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
    
    temp_dir = "/tmp/speech_enhancement"
    os.makedirs(temp_dir, exist_ok=True)
    os.makedirs(f"{temp_dir}/data/clean_speech", exist_ok=True)
    os.makedirs(f"{temp_dir}/data/noise", exist_ok=True)
    os.makedirs(f"{temp_dir}/models", exist_ok=True)
    
    print(f"üìÅ –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {temp_dir}")
    print("="*60)
    
    return temp_dir

def copy_data_to_tmp(drive_path, temp_dir):
    """–ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å Google –î–∏—Å–∫–∞ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã–π SSD"""
    print("\nüìÅ –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã–π SSD...")
    
    drive_data_path = os.path.join(drive_path, "data")
    
    if os.path.exists(drive_data_path):
        clean_src = os.path.join(drive_data_path, "clean_speech")
        noise_src = os.path.join(drive_data_path, "noise")
        
        clean_dst = os.path.join(temp_dir, "data/clean_speech")
        noise_dst = os.path.join(temp_dir, "data/noise")
        
        max_files = 10000
        
        def copy_files(src_dir, dst_dir, file_type="wav"):
            os.makedirs(dst_dir, exist_ok=True)
            files = glob.glob(os.path.join(src_dir, f"*.{file_type}"))[:max_files]
            
            print(f"–ö–æ–ø–∏—Ä—É–µ–º {len(files)} —Ñ–∞–π–ª–æ–≤ –∏–∑ {src_dir}...")
            
            for i, src_file in enumerate(files):
                if i % 100 == 0:
                    print(f"  –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ {i}/{len(files)} —Ñ–∞–π–ª–æ–≤")
                
                dst_file = os.path.join(dst_dir, os.path.basename(src_file))
                if not os.path.exists(dst_file):
                    shutil.copy2(src_file, dst_file)
            
            return len(files)
        
        clean_count = copy_files(clean_src, clean_dst, "wav")
        noise_count = copy_files(noise_src, noise_dst, "wav")
        
        print(f"‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ {clean_count} —á–∏—Å—Ç—ã—Ö –∏ {noise_count} —à—É–º–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
        return clean_dst, noise_dst
    else:
        print(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ {drive_data_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return None, None

def spectral_subtraction(noisy_spec, noise_estimate, alpha=1.5, beta=0.1):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–µ –≤—ã—á–∏—Ç–∞–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    mag_noisy = np.abs(noisy_spec)
    phase = np.angle(noisy_spec)
    
    # –ó–∞—â–∏—Ç–∞ —Ä–µ—á–∏ –æ—Ç —á—Ä–µ–∑–º–µ—Ä–Ω–æ–≥–æ –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è
    speech_mask = np.maximum(0, 1 - beta * noise_estimate / (mag_noisy + 1e-8))
    speech_mask = np.minimum(1, speech_mask)
    
    # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–µ –≤—ã—á–∏—Ç–∞–Ω–∏–µ
    mag_clean = np.maximum(0, mag_noisy - alpha * noise_estimate)
    mag_clean = mag_clean * speech_mask
    
    return mag_clean * np.exp(1j * phase)

def wiener_filter(stft_features, noise_estimate):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä –í–∏–Ω–µ—Ä–∞ –¥–ª—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    mag = np.abs(stft_features)
    phase = np.angle(stft_features)
    
    # –û—Ü–µ–Ω–∫–∞ –æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª/—à—É–º
    snr_estimate = np.maximum(0, mag**2 / (noise_estimate**2 + 1e-8) - 1)
    wiener_gain = snr_estimate / (snr_estimate + 1)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä
    mag_clean = mag * wiener_gain
    
    return mag_clean * np.exp(1j * phase)

def estimate_noise_from_audio(audio, sr=16000, n_fft=512, hop_length=256, win_length=512):
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —à—É–º–æ–≤–æ–π —Å–ø–µ–∫—Ç—Ä –∏–∑ –∞—É–¥–∏–æ (–ø–µ—Ä–≤—ã–µ 100 –º—Å)."""
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 100 –º—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —à—É–º–∞
    noise_samples = int(0.1 * sr)
    if len(audio) > noise_samples:
        noise_segment = audio[:noise_samples]
    else:
        noise_segment = audio
    
    noise_spec = librosa.stft(
        noise_segment,
        n_fft=n_fft,
        hop_length=hop_length,
        win_length=win_length,
        window='hann'
    )
    
    return np.mean(np.abs(noise_spec), axis=1, keepdims=True)

def process_single_file_with_pipeline(args):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —Å –ø–æ–ª–Ω—ã–º –∫–∞—Å–∫–∞–¥–æ–º: SS ‚Üí NN ‚Üí Wiener."""
    clean_path, noisy_path, target_frames = args
    
    try:
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ
        target_samples = target_frames * HOP_LENGTH
        target_seconds = target_samples / SR
        
        clean_audio = librosa.load(clean_path, sr=SR, duration=target_seconds)[0]
        noisy_audio = librosa.load(noisy_path, sr=SR, duration=target_seconds)[0]
        
        # 2. –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –¥–ª–∏–Ω—ã
        if len(clean_audio) < target_samples:
            pad_len = target_samples - len(clean_audio)
            clean_audio = np.pad(clean_audio, (0, pad_len), mode='constant')
        clean_audio = clean_audio[:target_samples]
        
        if len(noisy_audio) < target_samples:
            pad_len = target_samples - len(noisy_audio)
            noisy_audio = np.pad(noisy_audio, (0, pad_len), mode='constant')
        noisy_audio = noisy_audio[:target_samples]
        
        # 3. STFT
        clean_spec = librosa.stft(
            clean_audio,
            n_fft=N_FFT,
            hop_length=HOP_LENGTH,
            win_length=N_FFT,
            window='hann',
            center=False
        )
        
        noisy_spec = librosa.stft(
            noisy_audio,
            n_fft=N_FFT,
            hop_length=HOP_LENGTH,
            win_length=N_FFT,
            window='hann',
            center=False
        )
        
        # 4. –û—Ü–µ–Ω–∫–∞ —à—É–º–∞
        noise_estimate = estimate_noise_from_audio(noisy_audio, SR, N_FFT, HOP_LENGTH, N_FFT)
        
        # 5. –°–ü–ï–ö–¢–†–ê–õ–¨–ù–û–ï –í–´–ß–ò–¢–ê–ù–ò–ï (–ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞)
        preprocessed_spec = spectral_subtraction(
            noisy_spec, 
            noise_estimate,
            alpha=SPEC_SUBTRACTION_ALPHA,
            beta=SPEC_SUBTRACTION_BETA
        )
        
        # 6. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        # –ù–µ–π—Ä–æ—Å–µ—Ç—å –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è —É–ª—É—á—à–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –≤—ã—á–∏—Ç–∞–Ω–∏—è
        preprocessed_real = np.real(preprocessed_spec)
        preprocessed_imag = np.imag(preprocessed_spec)
        clean_real = np.real(clean_spec)
        clean_imag = np.imag(clean_spec)
        
        # 7. –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É
        if clean_spec.shape[1] != target_frames:
            if clean_spec.shape[1] > target_frames:
                clean_spec = clean_spec[:, :target_frames]
                preprocessed_spec = preprocessed_spec[:, :target_frames]
            else:
                pad_width = target_frames - clean_spec.shape[1]
                clean_spec = np.pad(clean_spec, ((0, 0), (0, pad_width)), mode='constant')
                preprocessed_spec = np.pad(preprocessed_spec, ((0, 0), (0, pad_width)), mode='constant')
        
        # 8. –§–∏–ª—å—Ç—Ä –í–∏–Ω–µ—Ä–∞ –Ω–∞ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–∏–≥–Ω–∞–ª–µ (—Ü–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
        # –≠—Ç–æ —Ç–æ, —á—Ç–æ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–æ–ª–∂–Ω–∞ –Ω–∞—É—á–∏—Ç—å—Å—è –ø—Ä–∏–±–ª–∏–∂–∞—Ç—å
        wiener_target = wiener_filter(clean_spec, noise_estimate)
        
        # 9. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        # –í—Ö–æ–¥: —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ –≤—ã—á—Ç–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (2 –∫–∞–Ω–∞–ª–∞: real, imag)
        # –¶–µ–ª—å: —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ñ–∏–ª—å—Ç—Ä–∞ –í–∏–Ω–µ—Ä–∞ –Ω–∞ —á–∏—Å—Ç–æ–º —Å–∏–≥–Ω–∞–ª–µ
        input_spec_2ch = np.stack([np.real(preprocessed_spec), np.imag(preprocessed_spec)], axis=-1)
        target_spec_2ch = np.stack([np.real(wiener_target), np.imag(wiener_target)], axis=-1)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        filename = os.path.basename(clean_path)
        if np.any(np.isnan(input_spec_2ch)) or np.any(np.isinf(input_spec_2ch)):
            print(f"‚ùå {filename}: NaN/Inf –≤ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            return None
        
        return input_spec_2ch, target_spec_2ch, noise_estimate
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ñ–∞–π–ª–µ {os.path.basename(clean_path)}: {str(e)[:100]}")
        return None

def prepare_data_pipeline_parallel(file_tuples, num_samples=1000, target_time_frames=256):
    """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–ª–Ω—ã–º –∫–∞—Å–∫–∞–¥–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    print(f"\n‚ö° –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –° –ö–ê–°–ö–ê–î–û–ú SS‚ÜíNN‚ÜíWIENER")
    print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {min(num_samples, len(file_tuples))} —Ñ–∞–π–ª–æ–≤")
    
    start_time = time.time()
    
    file_tuples = file_tuples[:min(num_samples, len(file_tuples))]
    args_list = [(clean, noisy, target_time_frames) for clean, noisy in file_tuples]
    
    input_specs = []
    target_specs = []
    noise_estimates = []
    successful = 0
    
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {multiprocessing.cpu_count()} —è–¥–µ—Ä CPU")
    
    with ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:
        results = list(executor.map(process_single_file_with_pipeline, args_list))
    
    for result in results:
        if result is not None:
            input_spec, target_spec, noise_est = result
            input_specs.append(input_spec)
            target_specs.append(target_spec)
            noise_estimates.append(noise_est)
            successful += 1
    
    elapsed = time.time() - start_time
    
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {successful}/{len(file_tuples)} —Ñ–∞–π–ª–æ–≤")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {elapsed:.1f} —Å–µ–∫—É–Ω–¥")
    
    if successful == 0:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞!")
    
    print(f"\nüìè –§–û–†–ú–ê –î–ê–ù–ù–´–•:")
    print(f"–í—Ö–æ–¥ (–ø–æ—Å–ª–µ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –≤—ã—á–∏—Ç–∞–Ω–∏—è): {input_specs[0].shape}")
    print(f"–¶–µ–ª—å (–∏–¥–µ–∞–ª—å–Ω—ã–π Wiener): {target_specs[0].shape}")
    
    return np.array(input_specs), np.array(target_specs), np.array(noise_estimates)

def create_context_windows_pipeline(data, context_frames=CONTEXT_FRAMES):
    """–°–æ–∑–¥–∞–µ—Ç –æ–∫–Ω–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –∫–∞—Å–∫–∞–¥–Ω–æ–π –º–æ–¥–µ–ª–∏."""
    num_samples, freq, time, channels = data.shape
    windows = []
    
    for i in range(num_samples):
        for t in range(time - context_frames + 1):
            window = data[i, :, t:t+context_frames, :]
            windows.append(window)
    
    return np.array(windows)

def create_center_frames_pipeline(data, context_frames=CONTEXT_FRAMES):
    """–°–æ–∑–¥–∞–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–µ –∫–∞–¥—Ä—ã –¥–ª—è Y –≤ –∫–∞—Å–∫–∞–¥–Ω–æ–π –º–æ–¥–µ–ª–∏."""
    num_samples, freq, time, channels = data.shape
    center_idx = context_frames // 2
    result = []
    
    for i in range(num_samples):
        for t in range(time - context_frames + 1):
            center_frame = data[i, :, t + center_idx, :]
            result.append(center_frame)
    
    return np.array(result)

def build_cascade_model(input_shape):
    """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–ª—è –∫–∞—Å–∫–∞–¥–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    inputs = layers.Input(shape=input_shape)  # (freq, context, 2)
    
    # Conv2D –¥–ª—è —á–∞—Å—Ç–æ—Ç–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    x = layers.Conv2D(32, (5, 3), padding='same', activation='relu')(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.1)(x)
    
    x = layers.Conv2D(64, (5, 3), padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.15)(x)
    
    x = layers.Conv2D(128, (5, 1), padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    
    # Residual block
    residual = x
    x = layers.Conv2D(128, (3, 1), padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.1)(x)
    
    x = layers.Conv2D(128, (3, 1), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Add()([x, residual])
    x = layers.Activation('relu')(x)
    
    x = layers.Conv2D(64, (3, 1), padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    
    # Attention mechanism
    attention = layers.GlobalAveragePooling2D()(x)
    attention = layers.Dense(32, activation='relu')(attention)
    attention = layers.Dense(64, activation='sigmoid')(attention)
    attention = layers.Reshape((1, 1, 64))(attention)
    x = layers.Multiply()([x, attention])
    
    # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
    x = layers.Conv2D(32, (3, 1), padding='same', activation='relu')(x)
    x = layers.Conv2D(2, (3, 1), padding='same', activation='tanh')(x)
    
    # –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –æ—Å—å
    output = tf.squeeze(x, axis=2)
    
    model = models.Model(inputs=inputs, outputs=output)
    return model

def complex_mae_loss(y_true, y_pred):
    """MAE loss –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö —á–∏—Å–µ–ª (–±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤—ã–π, —á–µ–º MSE)."""
    return tf.reduce_mean(tf.abs(y_true - y_pred))

def weighted_frequency_loss(y_true, y_pred):
    """–í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å —Å –±–æ–ª—å—à–∏–º –≤–µ—Å–æ–º –Ω–∞ –Ω–∏–∑–∫–∏—Ö —á–∞—Å—Ç–æ—Ç–∞—Ö."""
    # –°–æ–∑–¥–∞–µ–º –≤–µ—Å–∞: –±–æ–ª—å—à–µ –≤–µ—Å –Ω–∞ –Ω–∏–∑–∫–∏—Ö —á–∞—Å—Ç–æ—Ç–∞—Ö (–≥–¥–µ –±–æ–ª—å—à–µ —ç–Ω–µ—Ä–≥–∏–∏ —Ä–µ—á–∏)
    freq_weights = 1.0 + tf.linspace(0.0, 1.0, FREQ_BINS)
    freq_weights = tf.reshape(freq_weights, [1, FREQ_BINS, 1])
    
    error = tf.abs(y_true - y_pred)
    weighted_error = error * freq_weights
    
    return tf.reduce_mean(weighted_error)

# === –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ ===
if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    TEMP_DIR = setup_colab_environment()
    DRIVE_PROJECT_PATH = "/content/drive/MyDrive/diplom-project"
    
    # 1. –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    clean_dir, noise_dir = copy_data_to_tmp(DRIVE_PROJECT_PATH, TEMP_DIR)
    
    if clean_dir is None or noise_dir is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ. –í—ã—Ö–æ–¥.")
        exit(1)
    
    # 2. –°–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
    clean_files = glob.glob(os.path.join(clean_dir, "*.wav"))
    print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(clean_files)} —á–∏—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤")
    
    file_tuples = []
    for clean_file in clean_files:
        noisy_file = os.path.join(noise_dir, os.path.basename(clean_file))
        if os.path.exists(noisy_file):
            file_tuples.append((clean_file, noisy_file))
        else:
            print(f"‚ö†Ô∏è –®—É–º–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {noisy_file}")
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(file_tuples)} –ø–∞—Ä —Ñ–∞–π–ª–æ–≤")
    
    if len(file_tuples) == 0:
        print("‚ùå –ù–µ—Ç –ø–∞—Ä —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –í—ã—Ö–æ–¥.")
        exit(1)
    
    # 3. –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    if len(file_tuples) > MAX_SAMPLES:
        print(f"üîß –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ {MAX_SAMPLES} –ø–∞—Ä –¥–ª—è —Ç–µ—Å—Ç–∞")
        file_tuples = file_tuples[:MAX_SAMPLES]
    
    # 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∫–∞—Å–∫–∞–¥–æ–º
    print(f"\nüéØ –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –° –ö–ê–°–ö–ê–î–û–ú:")
    print(f"1. –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–µ –≤—ã—á–∏—Ç–∞–Ω–∏–µ (alpha={SPEC_SUBTRACTION_ALPHA}, beta={SPEC_SUBTRACTION_BETA})")
    print(f"2. –ù–µ–π—Ä–æ—Å–µ—Ç—å (—É–ª—É—á—à–µ–Ω–∏–µ)")
    print(f"3. –§–∏–ª—å—Ç—Ä –í–∏–Ω–µ—Ä–∞ (–∏–¥–µ–∞–ª—å–Ω–∞—è —Ü–µ–ª—å)")
    
    X_input, Y_target, noise_estimates = prepare_data_pipeline_parallel(
        file_tuples,
        num_samples=len(file_tuples),
        target_time_frames=TARGET_TIME_FRAMES
    )
    
    # 5. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    val_split = 0.15
    split_idx = int(len(X_input) * (1 - val_split))
    
    X_train, X_val = X_input[:split_idx], X_input[split_idx:]
    Y_train, Y_val = Y_target[:split_idx], Y_target[split_idx:]
    noise_train, noise_val = noise_estimates[:split_idx], noise_estimates[split_idx:]
    
    print(f"\nüìä –†–ê–ó–ú–ï–†–ù–û–°–¢–ò –î–ê–ù–ù–´–•:")
    print(f"X_train: {X_train.shape} (–≤—Ö–æ–¥ –ø–æ—Å–ª–µ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –≤—ã—á–∏—Ç–∞–Ω–∏—è)")
    print(f"Y_train: {Y_train.shape} (—Ü–µ–ª—å - –∏–¥–µ–∞–ª—å–Ω—ã–π Wiener)")
    print(f"X_val: {X_val.shape}")
    print(f"Y_val: {Y_val.shape}")
    
    # 6. –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –æ–∫–æ–Ω
    print(f"\nüîÑ –°–û–ó–î–ê–ù–ò–ï –û–ö–û–ù –° –ö–û–ù–¢–ï–ö–°–¢–û–ú ({CONTEXT_FRAMES} –∫–∞–¥—Ä–æ–≤)...")
    
    X_train_context = create_context_windows_pipeline(X_train, CONTEXT_FRAMES)
    X_val_context = create_context_windows_pipeline(X_val, CONTEXT_FRAMES)
    Y_train_center = create_center_frames_pipeline(Y_train, CONTEXT_FRAMES)
    Y_val_center = create_center_frames_pipeline(Y_val, CONTEXT_FRAMES)
    
    print(f"\n‚úÖ –î–ê–ù–ù–´–ï –ü–û–î–ì–û–¢–û–í–õ–ï–ù–´:")
    print(f"X_train_context: {X_train_context.shape}")
    print(f"Y_train_center:  {Y_train_center.shape}")
    print(f"X_val_context:   {X_val_context.shape}")
    print(f"Y_val_center:    {Y_val_center.shape}")
    
    # 7. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("\nü§ñ –°–û–ó–î–ê–ù–ò–ï –ö–ê–°–ö–ê–î–ù–û–ô –ú–û–î–ï–õ–ò")
    print("–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: Conv2D ‚Üí Residual ‚Üí Attention ‚Üí Output")
    
    input_shape = (FREQ_BINS, CONTEXT_FRAMES, 2)
    model = build_cascade_model(input_shape)
    
    # 8. –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏
    model.compile(
        optimizer=optimizers.Adam(learning_rate=0.001),
        loss=weighted_frequency_loss,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—É—é loss
        metrics=['mae', 'mse']
    )
    
    model.summary()
    
    # 9. Callbacks
    model_dir = os.path.join(TEMP_DIR, "models")
    os.makedirs(model_dir, exist_ok=True)
    
    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=15,
            restore_best_weights=True,
            verbose=1
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-6,
            verbose=1
        ),
        ModelCheckpoint(
            os.path.join(model_dir, "best_cascade_model.weights.h5"),
            monitor='val_loss',
            save_best_only=True,
            save_weights_only=True,
            verbose=1
        ),
        ModelCheckpoint(
            os.path.join(model_dir, "cascade_model_epoch_{epoch:02d}.h5"),
            save_freq='epoch',
            save_weights_only=True
        )
    ]
    
    # 10. –û–±—É—á–µ–Ω–∏–µ
    print("\nüöÄ –ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø –ö–ê–°–ö–ê–î–ù–û–ô –ú–û–î–ï–õ–ò")
    print("="*60)
    
    history = model.fit(
        X_train_context, Y_train_center,
        batch_size=min(BATCH_SIZE, len(X_train_context)),
        epochs=EPOCHS,
        validation_data=(X_val_context, Y_val_center),
        shuffle=True,
        verbose=1,
        callbacks=callbacks
    )
    
    # 11. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    final_model_path = os.path.join(model_dir, "final_cascade_model.h5")
    model.save(final_model_path)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_model_path}")
    
    # 12. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ
    print("\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –ü–†–ò–ú–ï–†–ï")
    test_idx = np.random.randint(0, len(X_val_context))
    test_input = X_val_context[test_idx:test_idx+1]
    test_target = Y_val_center[test_idx:test_idx+1]
    
    prediction = model.predict(test_input, verbose=0)
    
    mae = np.mean(np.abs(prediction - test_target))
    print(f"MAE –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –ø—Ä–∏–º–µ—Ä–µ: {mae:.4f}")
    
    # 13. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    try:
        import matplotlib.pyplot as plt
        
        plt.figure(figsize=(12, 8))
        
        plt.subplot(3, 2, 1)
        plt.imshow(test_input[0, :, :, 0], aspect='auto', origin='lower')
        plt.title("–í—Ö–æ–¥ (real)")
        plt.colorbar()
        
        plt.subplot(3, 2, 2)
        plt.imshow(test_input[0, :, :, 1], aspect='auto', origin='lower')
        plt.title("–í—Ö–æ–¥ (imag)")
        plt.colorbar()
        
        plt.subplot(3, 2, 3)
        plt.imshow(test_target[0, :, 0], aspect='auto', origin='lower')
        plt.title("–¶–µ–ª—å (real)")
        plt.colorbar()
        
        plt.subplot(3, 2, 4)
        plt.imshow(test_target[0, :, 1], aspect='auto', origin='lower')
        plt.title("–¶–µ–ª—å (imag)")
        plt.colorbar()
        
        plt.subplot(3, 2, 5)
        plt.imshow(prediction[0, :, 0], aspect='auto', origin='lower')
        plt.title("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (real)")
        plt.colorbar()
        
        plt.subplot(3, 2, 6)
        plt.imshow(prediction[0, :, 1], aspect='auto', origin='lower')
        plt.title("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (imag)")
        plt.colorbar()
        
        plt.tight_layout()
        plt.savefig(os.path.join(model_dir, "cascade_model_test.png"))
        print(f"‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
    except:
        print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é")
    
    # 14. –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\nüíæ –ö–û–ü–ò–†–û–í–ê–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ù–ê GOOGLE –î–ò–°–ö...")
    drive_models_dir = os.path.join(DRIVE_PROJECT_PATH, "models")
    os.makedirs(drive_models_dir, exist_ok=True)
    
    for file in glob.glob(os.path.join(model_dir, "*")):
        shutil.copy2(file, drive_models_dir)
    
    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {drive_models_dir}")
    
    # 15. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
    history_path = os.path.join(model_dir, "training_history.npy")
    np.save(history_path, history.history)
    
    print("\n" + "="*60)
    print("üéâ –û–ë–£–ß–ï–ù–ò–ï –ö–ê–°–ö–ê–î–ù–û–ô –ú–û–î–ï–õ–ò –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–µ –≤—ã—á–∏—Ç–∞–Ω–∏–µ ‚Üí –ù–µ–π—Ä–æ—Å–µ—Ç—å ‚Üí –§–∏–ª—å—Ç—Ä –í–∏–Ω–µ—Ä–∞")
    print(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {CONTEXT_FRAMES} –∫–∞–¥—Ä–æ–≤")
    print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –≤—ã—á–∏—Ç–∞–Ω–∏—è: alpha={SPEC_SUBTRACTION_ALPHA}, beta={SPEC_SUBTRACTION_BETA}")
    print(f"–û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å:")
    print(f"  Train Loss: {history.history['loss'][-1]:.4f}")
    print(f"  Val Loss:   {history.history['val_loss'][-1]:.4f}")
    print("="*60)
    
    # 16. –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
    print("\nüìã –ò–ù–°–¢–†–£–ö–¶–ò–Ø –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ:")
    print("1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏: model.load_weights('best_cascade_model.weights.h5')")
    print("2. –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ:")
    print("   - –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–µ –≤—ã—á–∏—Ç–∞–Ω–∏–µ –∫ —à—É–º–Ω–æ–º—É —Å–∏–≥–Ω–∞–ª—É")
    print("   - –ü–æ–¥–∞–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—å")
    print("   - (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Ñ–∏–ª—å—Ç—Ä –í–∏–Ω–µ—Ä–∞ –∫ –≤—ã—Ö–æ–¥—É –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
    print("\n–§–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–∞ –¥–ª—è –º–æ–¥–µ–ª–∏: (batch, freq_bins, context_frames, 2)")