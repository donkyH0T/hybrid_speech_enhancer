import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
import soundfile as sf
import os
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers

N_FFT = 512
HOP_LENGTH = 256

def load_and_preprocess_audio(file_path, sr=16000):
    audio, _ = librosa.load(file_path, sr=sr)
    audio = audio / (np.max(np.abs(audio)) + 1e-8)
    return audio

def audio_to_spectrogram(audio):
    spec = librosa.stft(audio, n_fft=N_FFT, hop_length=HOP_LENGTH)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –∏ –º–Ω–∏–º—É—é —á–∞—Å—Ç–∏
    real = np.real(spec)
    imag = np.imag(spec)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–æ –∫–∞–Ω–∞–ª–∞–º
    spec_2ch = np.stack([real, imag], axis=-1)
    return spec_2ch

def build_fast_denoise_model(input_shape):
    """–° –æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º–∏ —Å–≤—è–∑—è–º–∏ - –ª—É—á—à–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥–æ–ª–æ—Å"""
    from tensorflow.keras import layers, models
    
    inputs = layers.Input(shape=input_shape)
    
    # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π
    x = layers.Conv2D(32, (3, 3), padding='same')(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x_skip1 = x  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è skip connection
    
    # –í—Ç–æ—Ä–æ–π —Å–ª–æ–π
    x = layers.Conv2D(64, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    
    # –¢—Ä–µ—Ç–∏–π —Å–ª–æ–π + skip connection
    x = layers.Conv2D(32, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.add([x, x_skip1])  # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª!
    x = layers.ReLU()(x)
    
    outputs = layers.Conv2D(2, (3, 3), activation='tanh', padding='same')(x)
    
    model = models.Model(inputs, outputs)
    print(f"‚úÖ Fast –º–æ–¥–µ–ª—å —Å skip-connections —Å–æ–∑–¥–∞–Ω–∞")
    return model

def test_single_file_simple(model, clean_file_path, noisy_file_path, output_dir="single_test"):
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ (–±–µ–∑ —Å–ª–æ–∂–Ω–æ–π –æ–±—Ä–µ–∑–∫–∏)
    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è —Ñ–∞–π–ª–æ–≤ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã
    """
    
    import os
    import numpy as np
    import matplotlib.pyplot as plt
    import librosa
    import librosa.display
    import soundfile as sf
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ:")
    print(f"–ß–∏—Å—Ç—ã–π: {os.path.basename(clean_file_path)}")
    print(f"–®—É–º–Ω—ã–π: {os.path.basename(noisy_file_path)}")
    print("-" * 50)
    
    try:
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
        print("1. –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã...")
        clean_audio = load_and_preprocess_audio(clean_file_path)
        noisy_audio = load_and_preprocess_audio(noisy_file_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
        if len(clean_audio) != len(noisy_audio):
            print(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: —Ñ–∞–π–ª—ã —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã!")
            print(f"   –ß–∏—Å—Ç—ã–π: {len(clean_audio)} –æ—Ç—Å—á–µ—Ç–æ–≤")
            print(f"   –®—É–º–Ω—ã–π: {len(noisy_audio)} –æ—Ç—Å—á–µ—Ç–æ–≤")
            # –ù–æ –ø—Ä–æ–¥–æ–ª–∂–∏–º, –ø—Ä–æ—Å—Ç–æ –æ–±—Ä–µ–∂–µ–º –¥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π
            min_len = min(len(clean_audio), len(noisy_audio))
            clean_audio = clean_audio[:min_len]
            noisy_audio = noisy_audio[:min_len]
        
        print(f"   –ê—É–¥–∏–æ: {len(clean_audio)} –æ—Ç—Å—á–µ—Ç–æ–≤ ({len(clean_audio)/16000:.2f} —Å–µ–∫)")
        
        # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –í–°–ï–ì–û –∞—É–¥–∏–æ (–ø–æ –∫—É—Å–∫–∞–º –µ—Å–ª–∏ –¥–ª–∏–Ω–Ω–æ–µ)
        print("\n2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª—å—é...")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ 4 —Å–µ–∫—É–Ω–¥—ã (–∫–∞–∫ –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞)
        segment_duration = 4.0  # —Å–µ–∫—É–Ω–¥—ã
        segment_samples = int(segment_duration * 16000)  # 4 —Å–µ–∫ √ó 16000 –ì—Ü
        
        denoised_segments = []
        
        for start in range(0, len(clean_audio), segment_samples):
            end = start + segment_samples
            segment_noisy = noisy_audio[start:end]
            
            # –ï—Å–ª–∏ —Å–µ–≥–º–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –¥–æ–ø–æ–ª–Ω—è–µ–º
            if len(segment_noisy) < segment_samples:
                padding = segment_samples - len(segment_noisy)
                segment_noisy = np.pad(segment_noisy, (0, padding), mode='constant')
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
            segment_spec = audio_to_spectrogram(segment_noisy)
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Ä–∞–∑–º–µ—Ä—É –º–æ–¥–µ–ª–∏ (256 —Ñ—Ä–µ–π–º–æ–≤)
            target_frames = model.input_shape[2]
            current_frames = segment_spec.shape[1]
            
            if current_frames > target_frames:
                # –û–±—Ä–µ–∑–∞–µ–º –ø–æ —Ü–µ–Ω—Ç—Ä—É (—Ä–µ–¥–∫–æ, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
                start_frame = (current_frames - target_frames) // 2
                segment_spec = segment_spec[:, start_frame:start_frame + target_frames, :]
            elif current_frames < target_frames:
                # –î–æ–ø–æ–ª–Ω—è–µ–º (—Ç–æ–∂–µ —Ä–µ–¥–∫–æ)
                padding = target_frames - current_frames
                segment_spec = np.pad(segment_spec, ((0, 0), (0, padding), (0, 0)), mode='constant')
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª—å—é
            segment_denoised_spec = model.predict(
                np.expand_dims(segment_spec, 0), 
                verbose=0
            )[0]
            
            # –û–±—Ä–∞—Ç–Ω–æ –≤ –∞—É–¥–∏–æ
            def spec_to_audio(spec):
                real = spec[:, :, 0]
                imag = spec[:, :, 1]
                return librosa.istft(real + 1j * imag, hop_length=HOP_LENGTH)
            
            segment_denoised = spec_to_audio(segment_denoised_spec)
            
            # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –∏—Å—Ö–æ–¥–Ω–æ–π –¥–ª–∏–Ω—ã —Å–µ–≥–º–µ–Ω—Ç–∞ (–±–µ–∑ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è)
            segment_denoised = segment_denoised[:min(len(segment_noisy), len(segment_denoised))]
            denoised_segments.append(segment_denoised)
            
            if start == 0:
                print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω –ø–µ—Ä–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç: {len(segment_denoised)/16000:.2f} —Å–µ–∫")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        denoised_audio = np.concatenate(denoised_segments)
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –¥–ª–∏–Ω—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ
        denoised_audio = denoised_audio[:len(clean_audio)]
        
        print(f"   –û—á–∏—â–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ: {len(denoised_audio)} –æ—Ç—Å—á–µ—Ç–æ–≤ ({len(denoised_audio)/16000:.2f} —Å–µ–∫)")
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã
        print("\n3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã...")
        sr = 16000
        base_name = os.path.splitext(os.path.basename(clean_file_path))[0]
        
        sf.write(os.path.join(output_dir, f"{base_name}_clean.wav"), clean_audio, sr)
        sf.write(os.path.join(output_dir, f"{base_name}_noisy.wav"), noisy_audio, sr)
        sf.write(os.path.join(output_dir, f"{base_name}_denoised.wav"), denoised_audio, sr)
        
        print(f"   ‚úÖ –ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {output_dir}/")
        
        # 4. –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        print("\n4. –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞...")
        
        def calculate_snr(signal, noise):
            signal_power = np.mean(signal ** 2)
            noise_power = np.mean(noise ** 2)
            if noise_power < 1e-10:  # –∏–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0
                return float('inf')
            return 10 * np.log10(signal_power / noise_power)
        
        # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —à—É–º
        original_noise = noisy_audio - clean_audio
        original_snr = calculate_snr(clean_audio, original_noise)
        
        # –û—Å—Ç–∞–≤—à–∏–π—Å—è —à—É–º
        residual_noise = denoised_audio - clean_audio
        denoised_snr = calculate_snr(clean_audio, residual_noise)
        
        # MSE
        mse_original = np.mean(original_noise ** 2)
        mse_residual = np.mean(residual_noise ** 2)
        mse_reduction = (mse_original - mse_residual) / mse_original if mse_original > 0 else 0
        
        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"   SNR –∏—Å—Ö–æ–¥–Ω—ã–π: {original_snr:.2f} dB")
        print(f"   SNR –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {denoised_snr:.2f} dB")
        print(f"   –£–ª—É—á—à–µ–Ω–∏–µ SNR: {denoised_snr - original_snr:.2f} dB")
        print(f"   –£–º–µ–Ω—å—à–µ–Ω–∏–µ MSE: {mse_reduction*100:.1f}%")
        
        # 5. –ü—Ä–æ—Å—Ç–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        print("\n5. –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é...")
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        
        time = np.arange(len(clean_audio)) / sr
        
        # –í–æ–ª–Ω–æ–≤—ã–µ —Ñ–æ—Ä–º—ã
        axes[0, 0].plot(time, clean_audio, 'g', alpha=0.7, linewidth=0.5, label='–ß–∏—Å—Ç—ã–π')
        axes[0, 0].set_title('–ò—Å—Ö–æ–¥–Ω—ã–π —á–∏—Å—Ç—ã–π –∑–≤—É–∫')
        axes[0, 0].set_xlabel('–í—Ä–µ–º—è (—Å)')
        axes[0, 0].set_ylabel('–ê–º–ø–ª–∏—Ç—É–¥–∞')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        axes[0, 1].plot(time, noisy_audio, 'r', alpha=0.7, linewidth=0.5, label='–ó–∞—à—É–º–ª–µ–Ω–Ω—ã–π')
        axes[0, 1].set_title(f'–ó–∞—à—É–º–ª–µ–Ω–Ω—ã–π –∑–≤—É–∫ (SNR: {original_snr:.1f} dB)')
        axes[0, 1].set_xlabel('–í—Ä–µ–º—è (—Å)')
        axes[0, 1].set_ylabel('–ê–º–ø–ª–∏—Ç—É–¥–∞')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        axes[1, 0].plot(time, denoised_audio, 'b', alpha=0.7, linewidth=0.5, label='–û—á–∏—â–µ–Ω–Ω—ã–π')
        axes[1, 0].set_title(f'–û—á–∏—â–µ–Ω–Ω—ã–π –∑–≤—É–∫ (SNR: {denoised_snr:.1f} dB)')
        axes[1, 0].set_xlabel('–í—Ä–µ–º—è (—Å)')
        axes[1, 0].set_ylabel('–ê–º–ø–ª–∏—Ç—É–¥–∞')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # –®—É–º
        axes[1, 1].plot(time, original_noise, 'orange', alpha=0.5, linewidth=0.5, label='–ò—Å—Ö–æ–¥–Ω—ã–π —à—É–º')
        axes[1, 1].plot(time, residual_noise, 'purple', alpha=0.5, linewidth=0.5, label='–û—Å—Ç–∞–≤—à–∏–π—Å—è —à—É–º')
        axes[1, 1].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —à—É–º–∞')
        axes[1, 1].set_xlabel('–í—Ä–µ–º—è (—Å)')
        axes[1, 1].set_ylabel('–ê–º–ø–ª–∏—Ç—É–¥–∞')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.suptitle(
            f'–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏—è: {os.path.basename(clean_file_path)}\n'
            f'–£–ª—É—á—à–µ–Ω–∏–µ SNR: {denoised_snr - original_snr:.2f} dB | '
            f'–£–º–µ–Ω—å—à–µ–Ω–∏–µ —à—É–º–∞: {mse_reduction*100:.1f}%',
            fontsize=14
        )
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, f"{base_name}_results.png"), dpi=150, bbox_inches='tight')
        # plt.show()
        
        print(f"\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø–∞–ø–∫–µ: {output_dir}/")
        print(f"üéß –ü–æ—Å–ª—É—à–∞–π—Ç–µ: {base_name}_denoised.wav")
        
        return {
            'clean': clean_audio,
            'noisy': noisy_audio,
            'denoised': denoised_audio,
            'snr_improvement': denoised_snr - original_snr,
            'mse_reduction': mse_reduction
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return None

def build_light_denoise_model(input_shape):
    """
    –õ–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏—è 2D —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º
    input_shape: (—á–∞—Å—Ç–æ—Ç—ã, –≤—Ä–µ–º—è, 2) –≥–¥–µ 2 = real, imag —á–∞—Å—Ç–∏
    """
    inputs = layers.Input(shape=input_shape)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º 2D —Å–≤–µ—Ä—Ç–∫–æ–π (Conv2D –≤–º–µ—Å—Ç–æ Conv1D)
    # Block 1
    x = layers.Conv2D(32, (5, 5), padding='same')(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x1 = x  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è skip connection
    
    # Block 2
    x = layers.Conv2D(64, (5, 5), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.Dropout(0.1)(x)
    x2 = x
    
    # Middle block
    x = layers.Conv2D(128, (5, 5), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    
    # Decoder
    # Block 3
    x = layers.Conv2D(64, (5, 5), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.Dropout(0.1)(x)
    
    # –î–æ–±–∞–≤–ª—è–µ–º skip connection
    x = layers.add([x, x2])
    
    # Block 4
    x = layers.Conv2D(32, (5, 5), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    
    # –î–æ–±–∞–≤–ª—è–µ–º skip connection
    x = layers.add([x, x1])
    
    # Output block - 2 –∫–∞–Ω–∞–ª–∞ (real, imag)
    outputs = layers.Conv2D(2, (3, 3), activation='tanh', padding='same')(x)
    
    model = models.Model(inputs, outputs)
    return model


def build_minimal_denoise_model(input_shape):
    """
    –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å - –æ–±—É—á–∞–µ—Ç—Å—è –∑–∞ –º–∏–Ω—É—Ç—ã!
    """
    inputs = layers.Input(shape=input_shape)
    
    # –í—Å–µ–≥–æ 2 —Å–ª–æ—è!
    x = layers.Conv2D(8, (5, 5), padding='same', activation='relu')(inputs)
    x = layers.BatchNormalization()(x)
    
    outputs = layers.Conv2D(2, (5, 5), activation='tanh', padding='same')(x)
    
    model = models.Model(inputs, outputs)
    print(f"‚úÖ Minimal –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞")
    return model


if __name__ == "__main__":
    TARGET_TIME_FRAMES = 256
    FREQ_BINS = 257
    input_shape = (FREQ_BINS, TARGET_TIME_FRAMES, 2)
    
    print(f"Input shape: {input_shape}")
    model = build_fast_denoise_model(input_shape)
    print("–ó–∞–≥—Ä—É–∂–∞—é –æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞...")
    model.load_weights("models/best_light_model.weights.h5")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª
    clean_path = "data/clean_speech/p226_001.wav"
    noisy_path = "data/noise/p226_001.wav"
    
    print("\n" + "="*60)
    print("–¢–ï–°–¢ –ö–û–ù–ö–†–ï–¢–ù–û–ì–û –§–ê–ô–õ–ê")
    print("="*60)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 1: –ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
    results = test_single_file_simple(
        model=model,
        clean_file_path=clean_path,
        noisy_file_path=noisy_path,
        output_dir="test_p226_001"
    )
    
    if results:
        print("\nüéß –ß—Ç–æ–±—ã –ø–æ—Å–ª—É—à–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç:")
        print("1. –û—Ç–∫—Ä–æ–π—Ç–µ –ø–∞–ø–∫—É test_p226_001/")
        print("2. –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–∏—Ç–µ —Ñ–∞–π–ª—ã:")
        print("   - p226_001_clean.wav - –∏—Å—Ö–æ–¥–Ω—ã–π —á–∏—Å—Ç—ã–π")
        print("   - p226_001_noisy.wav - –∑–∞—à—É–º–ª–µ–Ω–Ω—ã–π")
        print("   - p226_001_denoised.wav - –æ—á–∏—â–µ–Ω–Ω—ã–π –º–æ–¥–µ–ª—å—é")
        print("3. –û—Ç–∫—Ä–æ–π—Ç–µ p226_001_results.png –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤")