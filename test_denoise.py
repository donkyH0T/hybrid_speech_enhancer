import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
import soundfile as sf
import os
import tensorflow as tf
from tensorflow.keras import layers, models
import warnings
warnings.filterwarnings('ignore')

# === –ü–ê–†–ê–ú–ï–¢–†–´ (–î–û–õ–ñ–ù–´ –°–û–í–ü–ê–î–ê–¢–¨ –° –û–ë–£–ß–ï–ù–ò–ï–ú!) ===
SR = 16000
N_FFT = 512
HOP_LENGTH = 256
CONTEXT_FRAMES = 5  # –î–û–õ–ñ–ù–û –ë–´–¢–¨ –¢–ê–ö –ñ–ï –ö–ê–ö –ü–†–ò –û–ë–£–ß–ï–ù–ò–ò!
FREQ_BINS = N_FFT // 2 + 1  # 257

def load_and_preprocess_audio(file_path, target_samples=None):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∞—É–¥–∏–æ."""
    audio, _ = librosa.load(file_path, sr=SR)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    audio = audio / (np.max(np.abs(audio)) + 1e-8)
    
    # –û–±—Ä–µ–∑–∞–µ–º/–¥–æ–ø–æ–ª–Ω—è–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if target_samples:
        if len(audio) < target_samples:
            audio = np.pad(audio, (0, target_samples - len(audio)), mode='constant')
        else:
            audio = audio[:target_samples]
    
    return audio

def create_context_windows(spec, context_frames):
    """–°–æ–∑–¥–∞–µ—Ç –æ–∫–Ω–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –æ–¥–Ω–æ–π —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã."""
    # spec shape: (freq, time, channels)
    time_frames = spec.shape[1]
    windows = []
    
    for t in range(time_frames - context_frames + 1):
        window = spec[:, t:t+context_frames, :]
        windows.append(window)
    
    return np.array(windows)  # (num_windows, freq, context_frames, channels)

def reconstruct_from_windows(windows, original_time_frames):
    """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–æ–ª–Ω—É—é —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É –∏–∑ –æ–∫–æ–Ω (–±–µ—Ä–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–µ –∫–∞–¥—Ä—ã)."""
    context_frames = windows.shape[2]
    center_idx = context_frames // 2
    freq_bins = windows.shape[1]
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É—Å—Ç—É—é —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
    reconstructed = np.zeros((freq_bins, original_time_frames, 2))
    weight_matrix = np.zeros((freq_bins, original_time_frames))
    
    # –°–∫–ª–∞–¥—ã–≤–∞–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–µ –∫–∞–¥—Ä—ã
    for i, window in enumerate(windows):
        center_frame = window[:, center_idx, :]
        reconstructed[:, i, :] += center_frame
        weight_matrix[:, i] += 1
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º (–¥–µ–ª–∏–º –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–ª–æ–∂–µ–Ω–∏–π)
    weight_matrix[weight_matrix == 0] = 1  # –∏–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0
    reconstructed = reconstructed / weight_matrix[:, :, np.newaxis]
    
    return reconstructed

def test_hybrid_model(model, clean_path, noisy_path, output_dir="hybrid_test"):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—É—é –º–æ–¥–µ–ª—å —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º."""
    import os
    import numpy as np
    import matplotlib.pyplot as plt
    import librosa
    import soundfile as sf
    
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–∏–±—Ä–∏–¥–Ω—É—é –º–æ–¥–µ–ª—å:")
    print(f"–ß–∏—Å—Ç—ã–π: {os.path.basename(clean_path)}")
    print(f"–®—É–º–Ω—ã–π: {os.path.basename(noisy_path)}")
    print(f"CONTEXT_FRAMES: {CONTEXT_FRAMES}")
    print("-" * 50)
    
    try:
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
        print("1. –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ...")
        clean_audio = load_and_preprocess_audio(clean_path)
        noisy_audio = load_and_preprocess_audio(noisy_path)
        
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        min_len = min(len(clean_audio), len(noisy_audio))
        clean_audio = clean_audio[:min_len]
        noisy_audio = noisy_audio[:min_len]
        
        print(f"   –î–ª–∏–Ω–∞: {min_len} –æ—Ç—Å—á–µ—Ç–æ–≤ ({min_len/SR:.2f} —Å–µ–∫)")
        
        # 2. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã
        print("\n2. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã...")
        
        def audio_to_spec(audio):
            spec = librosa.stft(audio, n_fft=N_FFT, hop_length=HOP_LENGTH)
            real = np.real(spec)
            imag = np.imag(spec)
            return np.stack([real, imag], axis=-1)  # (freq, time, 2)
        
        clean_spec = audio_to_spec(clean_audio)
        noisy_spec = audio_to_spec(noisy_audio)
        
        # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–∞–∑–º–µ—Ä—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
        if clean_spec.shape[1] != noisy_spec.shape[1]:
            print(f"‚ö†Ô∏è –†–∞–∑–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º!")
            print(f"   Clean: {clean_spec.shape[1]} –∫–∞–¥—Ä–æ–≤")
            print(f"   Noisy: {noisy_spec.shape[1]} –∫–∞–¥—Ä–æ–≤")
            # –ë–µ—Ä–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
            min_frames = min(clean_spec.shape[1], noisy_spec.shape[1])
            clean_spec = clean_spec[:, :min_frames, :]
            noisy_spec = noisy_spec[:, :min_frames, :]
        
        print(f"   –§–æ—Ä–º–∞ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã: {noisy_spec.shape}")
        
        # 3. –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –æ–∫–Ω–∞
        print("\n3. –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –æ–∫–Ω–∞...")
        
        # –í–∞–∂–Ω–æ: –Ω—É–∂–Ω–æ —á—Ç–æ–±—ã –±—ã–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if noisy_spec.shape[1] < CONTEXT_FRAMES:
            print(f"‚ùå –û–®–ò–ë–ö–ê: —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞!")
            print(f"   –ï—Å—Ç—å: {noisy_spec.shape[1]}, –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º: {CONTEXT_FRAMES}")
            return None
            
        noisy_windows = create_context_windows(noisy_spec, CONTEXT_FRAMES)
        
        print(f"   –°–æ–∑–¥–∞–Ω–æ {len(noisy_windows)} –æ–∫–æ–Ω")
        print(f"   –§–æ—Ä–º–∞ –æ–∫–Ω–∞: {noisy_windows[0].shape} (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å {model.input_shape[1:]})")
        
        # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª—å—é
        print("\n4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª—å—é...")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        batch_size = 32
        processed_windows = []
        
        for i in range(0, len(noisy_windows), batch_size):
            batch = noisy_windows[i:i+batch_size]
            predictions = model.predict(batch, verbose=0)
            processed_windows.append(predictions)
            
            if i == 0:
                print(f"   –ü–µ—Ä–≤—ã–π –±–∞—Ç—á –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
                print(f"   –í—Ö–æ–¥: {batch.shape}, –í—ã—Ö–æ–¥: {predictions.shape}")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        denoised_center_frames = np.concatenate(processed_windows, axis=0)
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(denoised_center_frames)} —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤")
        
        # 5. –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª–Ω—É—é —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
        print("\n5. –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª–Ω—É—é —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É...")
        
        # –ö–ê–ö –ú–ù–û–ì–û –ö–ê–î–†–û–í –ú–´ –î–û–õ–ñ–ù–´ –ü–û–õ–£–ß–ò–¢–¨?
        # –ï—Å–ª–∏ –±—ã–ª–æ T –∫–∞–¥—Ä–æ–≤ –∏ CONTEXT_FRAMES = 5,
        # —Ç–æ –ø–æ—Å–ª–µ create_context_windows –±—É–¥–µ—Ç T-4 –æ–∫–æ–Ω
        # –ò –ø–æ—Å–ª–µ reconstruct_from_windows –±—É–¥–µ—Ç T-4 –∫–∞–¥—Ä–æ–≤
        
        # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –Ω–∞ –≤—ã—Ö–æ–¥–µ:
        expected_frames = noisy_spec.shape[1] - CONTEXT_FRAMES + 1
        
        denoised_windows = []
        for center_frame in denoised_center_frames:
            window = np.zeros((FREQ_BINS, CONTEXT_FRAMES, 2))
            window[:, CONTEXT_FRAMES//2, :] = center_frame
            denoised_windows.append(window)
        
        denoised_windows = np.array(denoised_windows)
        denoised_spec = reconstruct_from_windows(denoised_windows, expected_frames)
        
        print(f"   –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞: {denoised_spec.shape}")
        print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞: {noisy_spec.shape}")
        
        # 6. –û–±—Ä–∞—Ç–Ω–æ –≤ –∞—É–¥–∏–æ
        print("\n6. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ –∞—É–¥–∏–æ...")
        
        def spec_to_audio(spec):
            real = spec[:, :, 0]
            imag = spec[:, :, 1]
            return librosa.istft(real + 1j * imag, hop_length=HOP_LENGTH, length=min_len)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º length=min_len –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –¥–ª–∏–Ω—ã
        denoised_audio = spec_to_audio(denoised_spec)
        
        # –¢–µ–ø–µ—Ä—å clean_audio –∏ denoised_audio –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã
        # –ù–æ –µ—Å–ª–∏ –Ω–µ—Ç - –æ–±—Ä–µ–∂–µ–º –¥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π
        final_len = min(len(clean_audio), len(denoised_audio))
        clean_audio = clean_audio[:final_len]
        noisy_audio = noisy_audio[:final_len]
        denoised_audio = denoised_audio[:final_len]
        
        print(f"   –ò—Ç–æ–≥–æ–≤–∞—è –¥–ª–∏–Ω–∞:")
        print(f"   Clean: {len(clean_audio)}")
        print(f"   Noisy: {len(noisy_audio)}")
        print(f"   Denoised: {len(denoised_audio)}")
        
        # 7. –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –†–ê–ó–ú–ï–†–û–í
        if len(clean_audio) != len(denoised_audio):
            print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —Ä–∞–∑–Ω—ã–µ –¥–ª–∏–Ω—ã!")
            print(f"   Clean: {len(clean_audio)}")
            print(f"   Denoised: {len(denoised_audio)}")
            # –î–µ–ª–∞–µ–º –∏—Ö –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏
            min_len_final = min(len(clean_audio), len(denoised_audio))
            clean_audio = clean_audio[:min_len_final]
            noisy_audio = noisy_audio[:min_len_final]
            denoised_audio = denoised_audio[:min_len_final]
        
        # 8. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("\n7. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
        base_name = os.path.splitext(os.path.basename(clean_path))[0]
        
        sf.write(os.path.join(output_dir, f"{base_name}_clean.wav"), clean_audio, SR)
        sf.write(os.path.join(output_dir, f"{base_name}_noisy.wav"), noisy_audio, SR)
        sf.write(os.path.join(output_dir, f"{base_name}_denoised.wav"), denoised_audio, SR)
        
        # 9. –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ (–¢–û–õ–¨–ö–û –ü–û–°–õ–ï –í–´–†–ê–í–ù–ò–í–ê–ù–ò–Ø!)
        print("\n8. –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏...")
        
        def calculate_snr(signal, noise):
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ä–∞–∑–º–µ—Ä—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
            if len(signal) != len(noise):
                min_len = min(len(signal), len(noise))
                signal = signal[:min_len]
                noise = noise[:min_len]
            
            signal_power = np.mean(signal ** 2)
            noise_power = np.mean(noise ** 2)
            if noise_power < 1e-10:
                return float('inf')
            return 10 * np.log10(signal_power / noise_power)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ –ø–µ—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º
        print(f"   –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è SNR:")
        print(f"   Clean: {len(clean_audio)}, Noisy: {len(noisy_audio)}")
        
        original_noise = noisy_audio - clean_audio
        residual_noise = denoised_audio - clean_audio
        
        print(f"   Original noise: {len(original_noise)}")
        print(f"   Residual noise: {len(residual_noise)}")
        
        original_snr = calculate_snr(clean_audio, original_noise)
        denoised_snr = calculate_snr(clean_audio, residual_noise)
        
        mse_original = np.mean(original_noise ** 2)
        mse_residual = np.mean(residual_noise ** 2)
        mse_reduction = (mse_original - mse_residual) / mse_original if mse_original > 0 else 0
        
        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"   –ò—Å—Ö–æ–¥–Ω—ã–π SNR: {original_snr:.2f} dB")
        print(f"   –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {denoised_snr:.2f} dB")
        print(f"   –£–ª—É—á—à–µ–Ω–∏–µ: {denoised_snr - original_snr:.2f} dB")
        print(f"   –£–º–µ–Ω—å—à–µ–Ω–∏–µ MSE: {mse_reduction*100:.1f}%")
        
        # 10. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        print("\n9. –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é...")
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        time_clean = np.arange(len(clean_audio)) / SR
        time_noisy = np.arange(len(noisy_audio)) / SR
        time_denoised = np.arange(len(denoised_audio)) / SR
        
        # –í–æ–ª–Ω–æ–≤—ã–µ —Ñ–æ—Ä–º—ã
        axes[0, 0].plot(time_clean, clean_audio, 'g', alpha=0.7, linewidth=0.5)
        axes[0, 0].set_title('–ò—Å—Ö–æ–¥–Ω—ã–π —á–∏—Å—Ç—ã–π –∑–≤—É–∫')
        axes[0, 0].set_xlabel('–í—Ä–µ–º—è (—Å)')
        axes[0, 0].grid(True, alpha=0.3)
        
        axes[0, 1].plot(time_noisy, noisy_audio, 'r', alpha=0.7, linewidth=0.5)
        axes[0, 1].set_title(f'–ó–∞—à—É–º–ª–µ–Ω–Ω—ã–π (SNR: {original_snr:.1f} dB)')
        axes[0, 1].set_xlabel('–í—Ä–µ–º—è (—Å)')
        axes[0, 1].grid(True, alpha=0.3)
        
        axes[1, 0].plot(time_denoised, denoised_audio, 'b', alpha=0.7, linewidth=0.5)
        axes[1, 0].set_title(f'–û—á–∏—â–µ–Ω–Ω—ã–π (SNR: {denoised_snr:.1f} dB)')
        axes[1, 0].set_xlabel('–í—Ä–µ–º—è (—Å)')
        axes[1, 0].grid(True, alpha=0.3)
        
        # –®—É–º (—É–±–µ–¥–∏–º—Å—è —á—Ç–æ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã)
        noise_time = np.arange(len(original_noise)) / SR
        axes[1, 1].plot(noise_time, original_noise, 'orange', alpha=0.5, linewidth=0.5, label='–ò—Å—Ö–æ–¥–Ω—ã–π')
        axes[1, 1].plot(noise_time, residual_noise, 'purple', alpha=0.5, linewidth=0.5, label='–û—Å—Ç–∞–≤—à–∏–π—Å—è')
        axes[1, 1].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —à—É–º–∞')
        axes[1, 1].set_xlabel('–í—Ä–µ–º—è (—Å)')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.suptitle(
            f'–ì–∏–±—Ä–∏–¥–Ω–∞—è –º–æ–¥–µ–ª—å: {os.path.basename(clean_path)}\n'
            f'–£–ª—É—á—à–µ–Ω–∏–µ SNR: {denoised_snr - original_snr:.2f} dB',
            fontsize=14
        )
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, f"{base_name}_results.png"), dpi=150)
        plt.close()
        
        print(f"\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤: {output_dir}/")
        
        return {
            'clean': clean_audio,
            'noisy': noisy_audio,
            'denoised': denoised_audio,
            'snr_improvement': denoised_snr - original_snr,
            'mse_reduction': mse_reduction
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return None

def build_better_hybrid_model(input_shape, context_frames=5):
    """–¢–∞ –∂–µ –º–æ–¥–µ–ª—å —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏"""
    inputs = layers.Input(shape=input_shape)
    input_center = layers.Lambda(lambda x: x[:, :, context_frames//2, :])(inputs)
    
    # Encoder
    x = layers.Conv2D(32, (3, 3), padding='same')(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(alpha=0.1)(x)
    skip1 = x
    
    x = layers.Conv2D(64, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(alpha=0.1)(x)
    skip2 = x
    
    x = layers.Conv2D(128, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(alpha=0.1)(x)
    
    # Bottleneck
    x = layers.Conv2D(128, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(alpha=0.1)(x)
    
    # Decoder
    x = layers.Conv2D(64, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(alpha=0.1)(x)
    x = layers.Add()([x, skip2])
    
    x = layers.Conv2D(32, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(alpha=0.1)(x)
    x = layers.Add()([x, skip1])
    
    # Output
    x = layers.Lambda(lambda x: x[:, :, context_frames//2, :])(x)
    x = layers.Conv1D(32, 3, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(alpha=0.1)(x)
    
    outputs = layers.Conv1D(2, 3, padding='same')(x)
    outputs = layers.Add()([input_center, outputs])
    outputs = layers.Activation('tanh')(outputs)
    
    return models.Model(inputs, outputs)

if __name__ == "__main__":
    print("="*60)
    print("–¢–ï–°–¢ –ì–ò–ë–†–ò–î–ù–û–ô –ú–û–î–ï–õ–ò –° –ö–û–ù–¢–ï–ö–°–¢–û–ú")
    print("="*60)
    
    # 1. –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –¢–û–ô –ñ–ï –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π
    input_shape = (FREQ_BINS, CONTEXT_FRAMES, 2)
    print(f"Input shape: {input_shape}")
    
    model = build_better_hybrid_model(input_shape, context_frames=CONTEXT_FRAMES)
    
    # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
    weights_path = "models/best_model.weights.h5"  # –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –ø—É—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π!
    print(f"\n–ó–∞–≥—Ä—É–∂–∞—é –≤–µ—Å–∞ –∏–∑: {weights_path}")
    
    if not os.path.exists(weights_path):
        print(f"‚ùå –§–∞–π–ª {weights_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å")
        exit(1)
    
    try:
        model.load_weights(weights_path)
        print("‚úÖ –í–µ—Å–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤: {e}")
        exit(1)
    
    # 3. –¢–µ—Å—Ç–∏—Ä—É–µ–º
    clean_path = "data/clean_speech/p226_007.wav"
    noisy_path = "data/noise/p226_007.wav"
    
    print(f"\n–¢–µ—Å—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã:")
    print(f"Clean: {clean_path}")
    print(f"Noisy: {noisy_path}")
    
    if not os.path.exists(clean_path) or not os.path.exists(noisy_path):
        print("‚ùå –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º")
        exit(1)
    
    # 4. –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç
    results = test_hybrid_model(
        model,
        clean_path,
        clean_path,
        "hybrid_model_test"
    )
    
    if results:
        print("\n" + "="*60)
        print("üéâ –¢–ï–°–¢ –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
        print("="*60)
        print(f"–£–ª—É—á—à–µ–Ω–∏–µ SNR: {results['snr_improvement']:.2f} dB")
        print(f"–£–º–µ–Ω—å—à–µ–Ω–∏–µ MSE: {results['mse_reduction']*100:.1f}%")
        print("\nüéß –î–ª—è –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è:")
        print("1. –û—Ç–∫—Ä–æ–π—Ç–µ –ø–∞–ø–∫—É 'hybrid_model_test/'")
        print("2. –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–∏—Ç–µ .wav —Ñ–∞–π–ª—ã")
        print("3. –û—Ç–∫—Ä–æ–π—Ç–µ .png –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤")